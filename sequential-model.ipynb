{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:07:35.929223Z",
     "iopub.status.busy": "2025-10-13T05:07:35.928949Z",
     "iopub.status.idle": "2025-10-13T05:07:56.128641Z",
     "shell.execute_reply": "2025-10-13T05:07:56.127871Z",
     "shell.execute_reply.started": "2025-10-13T05:07:35.929199Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 05:07:38.865905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760332059.315391      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760332059.472917      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.utils as ku \n",
    "import tensorflow as tf\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:09:27.014822Z",
     "iopub.status.busy": "2025-10-13T05:09:27.014265Z",
     "iopub.status.idle": "2025-10-13T05:09:27.018429Z",
     "shell.execute_reply": "2025-10-13T05:09:27.017823Z",
     "shell.execute_reply.started": "2025-10-13T05:09:27.014798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/10000-vietnamese-books/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:09:31.266593Z",
     "iopub.status.busy": "2025-10-13T05:09:31.265945Z",
     "iopub.status.idle": "2025-10-13T05:09:31.270522Z",
     "shell.execute_reply": "2025-10-13T05:09:31.269802Z",
     "shell.execute_reply.started": "2025-10-13T05:09:31.266568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    #Lower text\n",
    "    text = text.lower() \n",
    "    #Remove url \n",
    "    text = re.sub(r\"https?://\\S+\", '', text)\n",
    "    #Remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-ZÀ-ỹ\\s]\", \" \", text)\n",
    "    #Strip extra space \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:09:33.391482Z",
     "iopub.status.busy": "2025-10-13T05:09:33.390894Z",
     "iopub.status.idle": "2025-10-13T05:09:34.360232Z",
     "shell.execute_reply": "2025-10-13T05:09:34.359426Z",
     "shell.execute_reply.started": "2025-10-13T05:09:33.391460Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus built successfully!\n",
      "Number of sentences: 11393\n",
      "Example: ['mạc can', 'nhà ảo thuật', 'có một cậu bé muốn học vài trò ảo thuật nhưng không tìm đâu ra trường và thầy dạy', 'một hôm rỗi rảnh người cha chở cậu con trai nhỏ xíu khoảng tuổi ngồi háo hức sau yên xe honda', 'vòng quanh đường phố một lúc đang bình thường thì tự nhiên chiếc xe khục khịch ho khan dừng lại đầu hẻm như là có hẹn trước ngay chóc tiệm thuốc tây và cái tủ bán thuốc lá']\n"
     ]
    }
   ],
   "source": [
    "#Build corpus with 10 files\n",
    "corpus = []\n",
    "max_files = 10\n",
    "for i, file_name in enumerate(os.listdir(data_path)):\n",
    "    if i >= max_files:\n",
    "        break\n",
    "\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        for line in file:\n",
    "            sentences = line.split(\".\")\n",
    "            for sentence in sentences:\n",
    "                cleaned = preprocess(sentence)\n",
    "                if cleaned:                        \n",
    "                    corpus.append(cleaned)\n",
    "\n",
    "print(\"Corpus built successfully!\")\n",
    "print(\"Number of sentences:\", len(corpus))\n",
    "print(\"Example:\", corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:09:36.991247Z",
     "iopub.status.busy": "2025-10-13T05:09:36.990961Z",
     "iopub.status.idle": "2025-10-13T05:09:37.267160Z",
     "shell.execute_reply": "2025-10-13T05:09:37.266336Z",
     "shell.execute_reply.started": "2025-10-13T05:09:36.991225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 7064\n"
     ]
    }
   ],
   "source": [
    "corpus = list(filter(None, corpus))\n",
    "text = \" \".join(corpus)\n",
    "#Tokenization \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. LSTM for Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:09:39.390571Z",
     "iopub.status.busy": "2025-10-13T05:09:39.390313Z",
     "iopub.status.idle": "2025-10-13T05:09:40.058431Z",
     "shell.execute_reply": "2025-10-13T05:09:40.057606Z",
     "shell.execute_reply.started": "2025-10-13T05:09:39.390552Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 291487\n"
     ]
    }
   ],
   "source": [
    "#Input senquence for next word prediction \n",
    "input_sequence = []\n",
    "for line in corpus: \n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequence.append(n_gram_sequence)\n",
    "\n",
    "print(\"Total sequences:\", len(input_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:09:42.416310Z",
     "iopub.status.busy": "2025-10-13T05:09:42.415581Z",
     "iopub.status.idle": "2025-10-13T05:09:44.257974Z",
     "shell.execute_reply": "2025-10-13T05:09:44.257151Z",
     "shell.execute_reply.started": "2025-10-13T05:09:42.416284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 321\n",
      "X shape: (291487, 320)\n",
      "y shape: (291487, 7064)\n"
     ]
    }
   ],
   "source": [
    "#Pad sequence \n",
    "max_sequence_len = max([len(x) for x in input_sequence])\n",
    "input_sequence = np.array(pad_sequences(input_sequence, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "X = input_sequence[:, :-1]\n",
    "y = input_sequence[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "print(\"Max sequence length:\", max_sequence_len)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:09:50.892490Z",
     "iopub.status.busy": "2025-10-13T05:09:50.892220Z",
     "iopub.status.idle": "2025-10-13T05:09:54.896114Z",
     "shell.execute_reply": "2025-10-13T05:09:54.895584Z",
     "shell.execute_reply.started": "2025-10-13T05:09:50.892468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760332192.976708      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1760332192.977389      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">904,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">167,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7064</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,066,664</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m904,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m167,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7064\u001b[0m)           │     \u001b[38;5;34m1,066,664\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,256</span> (8.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,138,256\u001b[0m (8.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,256</span> (8.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,138,256\u001b[0m (8.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Build LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words, output_dim=128),\n",
    "    LSTM(150),\n",
    "    Dropout(0.2),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_sequence_len - 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:10:00.597731Z",
     "iopub.status.busy": "2025-10-13T05:10:00.597440Z",
     "iopub.status.idle": "2025-10-13T05:49:16.888271Z",
     "shell.execute_reply": "2025-10-13T05:49:16.887587Z",
     "shell.execute_reply.started": "2025-10-13T05:10:00.597708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760332231.696009      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 31ms/step - accuracy: 0.0270 - loss: 6.7785\n",
      "Epoch 2/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.1199 - loss: 5.7117\n",
      "Epoch 3/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.1683 - loss: 5.2168\n",
      "Epoch 4/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.1894 - loss: 4.9321\n",
      "Epoch 5/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2043 - loss: 4.7359\n",
      "Epoch 6/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2156 - loss: 4.5793\n",
      "Epoch 7/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2269 - loss: 4.4448\n",
      "Epoch 8/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2359 - loss: 4.3417\n",
      "Epoch 9/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2448 - loss: 4.2381\n",
      "Epoch 10/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2533 - loss: 4.1557\n",
      "Epoch 11/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2737 - loss: 3.9479\n",
      "Epoch 14/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 34ms/step - accuracy: 0.2788 - loss: 3.9038\n",
      "Epoch 15/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2872 - loss: 3.8351\n",
      "Epoch 16/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2903 - loss: 3.8002\n",
      "Epoch 17/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.2957 - loss: 3.7564\n",
      "Epoch 18/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3014 - loss: 3.7050\n",
      "Epoch 19/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3048 - loss: 3.6701\n",
      "Epoch 20/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3087 - loss: 3.6407\n",
      "Epoch 21/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3134 - loss: 3.6038\n",
      "Epoch 22/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3171 - loss: 3.5749\n",
      "Epoch 23/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3211 - loss: 3.5401\n",
      "Epoch 24/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3243 - loss: 3.5172\n",
      "Epoch 25/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3279 - loss: 3.4854\n",
      "Epoch 26/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3312 - loss: 3.4562\n",
      "Epoch 27/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3337 - loss: 3.4377\n",
      "Epoch 28/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3377 - loss: 3.4126\n",
      "Epoch 29/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3399 - loss: 3.3955\n",
      "Epoch 30/30\n",
      "\u001b[1m2278/2278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 34ms/step - accuracy: 0.3424 - loss: 3.3716\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=30, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T06:05:35.293200Z",
     "iopub.status.busy": "2025-10-13T06:05:35.292702Z",
     "iopub.status.idle": "2025-10-13T06:05:37.635974Z",
     "shell.execute_reply": "2025-10-13T06:05:37.635132Z",
     "shell.execute_reply.started": "2025-10-13T06:05:35.293175Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text Example:\n",
      "tôi là một người hùng theo lối sống trong khi đó có một người dân chúng ở đây có thể có thể dùng những người khác nhau để có thể tự thân\n"
     ]
    }
   ],
   "source": [
    "#Generate text\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)[0]\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                seed_text += \" \" + word\n",
    "                break\n",
    "    return seed_text\n",
    "\n",
    "print(\"\\nGenerated Text Example:\")\n",
    "print(generate_text(\"tôi là\", 30, model, max_sequence_len))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3046745,
     "sourceId": 5236465,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
